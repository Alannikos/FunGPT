import os
import sys
import time
import torch
from dataclasses import asdict
import streamlit as st
from audio_recorder_streamlit import audio_recorder

sys.path.append("/root/Project_FunGPT/FunGPT")
from Utils.common_utils import get_avatar, combine_history, combine_history_p2


def get_audio_input():
    with st.sidebar:
        st.markdown("---")
        st.title("è¯­éŸ³è¾“å…¥")
        translating_placeholder = st.empty()

        # ###################################
        #           è¯­éŸ³è¾“å…¥æ¨¡å—
        # ###################################

        with st.container():
            st.markdown("#### å½•éŸ³åŒºåŸŸ")
            audio_file = audio_recorder('ğŸŒŸ', key="record")
            st.markdown("---")
        
        with st.container():
            st.markdown("#### ğŸ“ è½¬æ¢ç»“æœ")
            text_placeholder = st.empty()
            edited_text = st.session_state.get('edited_text', "")  # ç”¨äºç¼–è¾‘åçš„æ–‡æœ¬
            st.markdown("---")

        with st.container():
            st.markdown("#### âœ‰ï¸ å‘é€")
            send_button = st.button("ğŸ“¬ å‘é€", key="send_button")

        # å¦‚æœå½•åˆ¶äº†éŸ³é¢‘ï¼Œåˆ™è¿›è¡Œè½¬æ¢
        if audio_file:
            translating_placeholder = st.empty()

            # 2024/10/1 å¼‚å¸¸å¤„ç†æœºåˆ¶
            try:
                user_wav_path = st.session_state.ASR_Model.save_wavs(audio_file)
                transcribed_text = st.session_state.ASR_Model.generate(user_wav_path)
                
                # æ˜¾ç¤ºå¹¶å…è®¸ç”¨æˆ·ç¼–è¾‘è½¬æ¢åçš„æ–‡æœ¬
                edited_text = text_placeholder.text_area(
                    label="è¯†åˆ«åæ–‡å­—", 
                    value=transcribed_text,
                    height=100,
                    key="transcribed_text"
                )

                st.session_state.edited_text = edited_text

                # å‘é€æ–‡æœ¬
                if send_button:
                    return edited_text
                else:
                    return None

            except Exception as e:
                translating_placeholder.info("â— ASRæ¨¡å‹æœªåŠ è½½æˆ–åŠ è½½å¤±è´¥...")
                time.sleep(2)
                translating_placeholder.empty()

    return None

def show_dialog_interface(user_input, mode=1):
    
    # å¦‚æœæœ‰ç”¨æˆ·è¾“å…¥,å¤„ç†å®ƒ
    if user_input:
        with st.chat_message('user', avatar=get_avatar("person2")):
            st.markdown(user_input)
        if mode == 1:
            new_history = combine_history(user_input)
        else:
            new_history = combine_history_p2(user_input)
        st.session_state.chat_history.append({'role': 'user', 'content': user_input})

        # 2024/10/1 å¼‚å¸¸å¤„ç†æœºåˆ¶
        model_placeholder = st.empty()
        try:
            wav_path = None
            with st.chat_message('robot', avatar=get_avatar("person1")):
                message_placeholder = st.empty()
                for cur_response in st.session_state.LLM_Model.generate(new_history, **asdict(st.session_state.llm_config['config'])):
                    message_placeholder.markdown(cur_response)

                # ###################################
                #           ç”Ÿæˆè¯­éŸ³æ¨¡å—
                # ###################################
                if st.session_state.tts_config is not None:
                    with st.spinner():
                        wav_path = st.session_state.TTS_Model.generate(cur_response, speed=st.session_state.tts_config['speed'])
                        st.session_state.TTS_Model.show_audio(wav_path)

            st.session_state.chat_history.append({'role': 'robot', 'content': cur_response, 'wav_path': wav_path})
            torch.cuda.empty_cache()
        except Exception as e:
            model_placeholder.info("â—LLMæ¨¡å‹æœªåŠ è½½æˆ–åŠ è½½å¤±è´¥...")
            time.sleep(2)
            model_placeholder.empty()

def handle_user_input(mode=1):
    user_input = None
    input_type = None

    # å°è¯•è·å–è¯­éŸ³è¾“å…¥
    audio_input = get_audio_input()
    if audio_input:
        user_input = audio_input
        input_type = "audio"

    # å¦‚æœæ²¡æœ‰è¯­éŸ³è¾“å…¥,å°è¯•è·å–æ–‡å­—è¾“å…¥
    if not user_input:
        text_input = st.chat_input('æ¬¢è¿å’Œæˆ‘äº¤æµo~')
        if text_input:
            user_input = text_input
            input_type = "text"

    # å±•ç¤ºå¯¹è¯ç•Œé¢
    show_dialog_interface(user_input, mode)